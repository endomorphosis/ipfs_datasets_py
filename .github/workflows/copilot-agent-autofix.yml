name: Copilot Agent Auto-Healing

on:
  workflow_run:
    # NOTE: GitHub Actions does NOT support wildcards like ["*"] in workflow_run triggers.
    # This list must be explicitly maintained. To update this list automatically, run:
    # python3 .github/scripts/generate_workflow_list.py yaml
    workflows:
      - "ARM64 Self-Hosted Runner"
      - "Docker Build and Test"
      - "Docker Build and Test (Multi-Platform)"
      - "Documentation Maintenance"
      - "GPU-Enabled Tests"
      - "GraphRAG Production CI/CD"
      - "MCP Dashboard Automated Tests"
      - "MCP Endpoints Integration Tests"
      - "PDF Processing Pipeline CI/CD"
      - "PDF Processing and MCP Tools CI"
      - "Publish Python Package"
      - "Self-Hosted Runner Test"
      - "Self-Hosted Runner Validation"
      - "Test Datasets ARM64 Runner"
    types:
      - completed
  workflow_dispatch:
    inputs:
      workflow_name:
        description: 'Name of the failed workflow to analyze'
        required: false
        type: string
      run_id:
        description: 'Specific workflow run ID to analyze'
        required: false
        type: string
      force_create_pr:
        description: 'Force create PR even if confidence is low'
        required: false
        default: false
        type: boolean

permissions:
  contents: write
  pull-requests: write
  issues: write
  actions: read

env:
  PYTHON_VERSION: '3.10'

jobs:
  autofix-with-copilot-agent:
    runs-on: [self-hosted, linux, x64]
    container:
      image: python:3.10-slim
      options: --user root
    # Only run if the triggering workflow failed and it's not another auto-fix workflow
    if: >
      github.event_name == 'workflow_dispatch' || 
      (github.event.workflow_run.conclusion == 'failure' && 
       !contains(github.event.workflow_run.name, 'Auto-Healing') &&
       !contains(github.event.workflow_run.name, 'Auto-Fix'))
    
    steps:
      - name: Debug workflow trigger information
        run: |
          echo "## 🔍 Workflow Trigger Debug Information" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Event Information" >> $GITHUB_STEP_SUMMARY
          echo "- **Event Name**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow Run Conclusion**: ${{ github.event.workflow_run.conclusion }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow Run Event**: ${{ github.event.workflow_run.event }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow Run Name**: ${{ github.event.workflow_run.name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow Run ID**: ${{ github.event.workflow_run.id }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Condition Checks" >> $GITHUB_STEP_SUMMARY
          echo "- **Is workflow_dispatch**: ${{ github.event_name == 'workflow_dispatch' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Conclusion is failure**: ${{ github.event.workflow_run.conclusion == 'failure' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Name doesn't contain Auto-Healing**: ${{ !contains(github.event.workflow_run.name, 'Auto-Healing') }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Name doesn't contain Auto-Fix**: ${{ !contains(github.event.workflow_run.name, 'Auto-Fix') }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **This workflow is running because all conditions were met**" >> $GITHUB_STEP_SUMMARY
      
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install PyYAML requests
      
      - name: Check for duplicate processing
        id: check_duplicate
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get the run ID we're checking
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            if [ -n "${{ github.event.inputs.run_id }}" ]; then
              RUN_ID="${{ github.event.inputs.run_id }}"
            else
              WORKFLOW_NAME="${{ github.event.inputs.workflow_name }}"
              RUN_ID=$(gh run list --workflow="$WORKFLOW_NAME" --status=failure --limit=1 --json databaseId --jq '.[0].databaseId' || echo "")
            fi
          else
            RUN_ID="${{ github.event.workflow_run.id }}"
          fi
          
          if [ -z "$RUN_ID" ]; then
            echo "❌ No workflow run ID found - skipping"
            echo "should_skip=true" >> $GITHUB_OUTPUT
            echo "skip_reason=no_run_id" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Check if we've already processed this run
          # Look for existing PRs or issues that reference this run ID
          EXISTING_PRS=$(gh pr list --search "Run ID: $RUN_ID in:body" --state all --json number --jq 'length')
          
          if [ "$EXISTING_PRS" -gt 0 ]; then
            echo "⚠️  Run $RUN_ID already has $EXISTING_PRS fix PR(s) - skipping duplicate processing"
            echo "should_skip=true" >> $GITHUB_OUTPUT
            echo "skip_reason=already_processed" >> $GITHUB_OUTPUT
            
            echo "## ⏭️ Skipping Duplicate Processing" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "This workflow run has already been analyzed and has existing fix PR(s)." >> $GITHUB_STEP_SUMMARY
            echo "- **Run ID**: $RUN_ID" >> $GITHUB_STEP_SUMMARY
            echo "- **Existing PRs**: $EXISTING_PRS" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          
          echo "should_skip=false" >> $GITHUB_OUTPUT
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
      
      - name: Get workflow run details
        id: get_run_details
        if: steps.check_duplicate.outputs.should_skip != 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          RUN_ID="${{ steps.check_duplicate.outputs.run_id }}"
          
          # Get workflow details
          WORKFLOW_NAME=$(gh run view $RUN_ID --json workflowName --jq '.workflowName')
          HEAD_BRANCH=$(gh run view $RUN_ID --json headBranch --jq '.headBranch')
          HEAD_SHA=$(gh run view $RUN_ID --json headSha --jq '.headSha')
          
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
          echo "workflow_name=$WORKFLOW_NAME" >> $GITHUB_OUTPUT
          echo "head_branch=$HEAD_BRANCH" >> $GITHUB_OUTPUT
          echo "head_sha=$HEAD_SHA" >> $GITHUB_OUTPUT
          
          echo "## Workflow Failure Detected" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow**: $WORKFLOW_NAME" >> $GITHUB_STEP_SUMMARY
          echo "- **Run ID**: $RUN_ID" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: $HEAD_BRANCH" >> $GITHUB_STEP_SUMMARY
          echo "- **SHA**: $HEAD_SHA" >> $GITHUB_STEP_SUMMARY
      
      - name: Check workflow eligibility
        id: check_eligibility
        if: steps.check_duplicate.outputs.should_skip != 'true'
        run: |
          WORKFLOW_NAME="${{ steps.get_run_details.outputs.workflow_name }}"
          
          # Load configuration
          CONFIG_FILE=".github/workflows/workflow-auto-fix-config.yml"
          
          # Check if workflow is in excluded list
          if [ -f "$CONFIG_FILE" ]; then
            # Extract excluded workflows (if any)
            EXCLUDED=$(python3 -c "
          import yaml
          import sys
          try:
              with open('$CONFIG_FILE') as f:
                  config = yaml.safe_load(f)
                  excluded = config.get('excluded_workflows', [])
                  if '$WORKFLOW_NAME' in excluded:
                      print('excluded')
                      sys.exit(0)
                  print('eligible')
          except Exception as e:
              print('eligible')  # If config can't be read, allow processing
          " 2>/dev/null)
            
            if [ "$EXCLUDED" = "excluded" ]; then
              echo "⚠️  Workflow '$WORKFLOW_NAME' is in excluded list - skipping"
              echo "should_process=false" >> $GITHUB_OUTPUT
              
              echo "## ⏭️ Workflow Excluded" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "The workflow '$WORKFLOW_NAME' is in the excluded workflows list." >> $GITHUB_STEP_SUMMARY
              echo "To enable auto-fix for this workflow, remove it from \`excluded_workflows\` in $CONFIG_FILE" >> $GITHUB_STEP_SUMMARY
              exit 0
            fi
          fi
          
          echo "should_process=true" >> $GITHUB_OUTPUT
          echo "✅ Workflow '$WORKFLOW_NAME' is eligible for auto-fix" >> $GITHUB_STEP_SUMMARY
      
      - name: Download workflow logs
        id: download_logs
        if: steps.check_duplicate.outputs.should_skip != 'true' && steps.check_eligibility.outputs.should_process == 'true' && steps.get_run_details.outputs.run_id != ''
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          RUN_ID="${{ steps.get_run_details.outputs.run_id }}"
          
          echo "📥 Downloading logs for run $RUN_ID..."
          mkdir -p /tmp/workflow_logs
          
          # Get failed jobs
          gh run view $RUN_ID --json jobs --jq '.jobs[] | select(.conclusion == "failure") | .databaseId' > /tmp/failed_jobs.txt
          
          if [ ! -s /tmp/failed_jobs.txt ]; then
            echo "No failed jobs found"
            echo "has_failures=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "has_failures=true" >> $GITHUB_OUTPUT
          
          # Download logs for each failed job
          while IFS= read -r job_id; do
            if [ -n "$job_id" ]; then
              echo "Downloading logs for job $job_id..."
              gh run view $RUN_ID --log --job $job_id > "/tmp/workflow_logs/job_${job_id}.log" 2>&1 || true
            fi
          done < /tmp/failed_jobs.txt
          
          # Create a summary of failures
          echo "## Failed Jobs Summary" > /tmp/workflow_logs/summary.txt
          gh run view $RUN_ID --json jobs --jq '.jobs[] | select(.conclusion == "failure") | "### \(.name)\n- Status: \(.conclusion)\n- Steps: \(.steps[] | select(.conclusion == "failure") | .name)\n"' >> /tmp/workflow_logs/summary.txt
          
          cat /tmp/workflow_logs/summary.txt
      
      - name: Analyze workflow failure
        id: analyze_failure
        if: steps.download_logs.outputs.has_failures == 'true'
        run: |
          python .github/scripts/analyze_workflow_failure.py \
            --run-id "${{ steps.get_run_details.outputs.run_id }}" \
            --workflow-name "${{ steps.get_run_details.outputs.workflow_name }}" \
            --logs-dir /tmp/workflow_logs \
            --output /tmp/failure_analysis.json
          
          if [ -f /tmp/failure_analysis.json ]; then
            echo "analysis_available=true" >> $GITHUB_OUTPUT
            
            # Extract key findings for summary
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## Failure Analysis" >> $GITHUB_STEP_SUMMARY
            python -c "
          import json
          with open('/tmp/failure_analysis.json') as f:
              data = json.load(f)
              print('- **Error Type**: ' + data.get('error_type', 'Unknown'))
              print('- **Root Cause**: ' + data.get('root_cause', 'Not identified'))
              print('- **Fix Confidence**: ' + str(data.get('fix_confidence', 0)) + '%')
          " >> $GITHUB_STEP_SUMMARY
          else
            echo "analysis_available=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Generate fix proposal
        id: generate_fix
        if: steps.analyze_failure.outputs.analysis_available == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python .github/scripts/generate_workflow_fix.py \
            --analysis /tmp/failure_analysis.json \
            --workflow-name "${{ steps.get_run_details.outputs.workflow_name }}" \
            --output /tmp/fix_proposal.json
          
          if [ -f /tmp/fix_proposal.json ]; then
            echo "fix_available=true" >> $GITHUB_OUTPUT
            
            # Extract fix details
            FIX_BRANCH=$(python -c "import json; print(json.load(open('/tmp/fix_proposal.json'))['branch_name'])")
            FIX_TITLE=$(python -c "import json; print(json.load(open('/tmp/fix_proposal.json'))['pr_title'])")
            
            echo "fix_branch=$FIX_BRANCH" >> $GITHUB_OUTPUT
            echo "fix_title=$FIX_TITLE" >> $GITHUB_OUTPUT
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## Fix Proposal" >> $GITHUB_STEP_SUMMARY
            echo "- **Branch**: \`$FIX_BRANCH\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Title**: $FIX_TITLE" >> $GITHUB_STEP_SUMMARY
          else
            echo "fix_available=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Create issue with failure details and assign to Copilot
        id: create_issue
        if: steps.generate_fix.outputs.fix_available == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          WORKFLOW_NAME="${{ steps.get_run_details.outputs.workflow_name }}"
          RUN_ID="${{ steps.get_run_details.outputs.run_id }}"
          
          # Read analysis for issue body
          ANALYSIS=$(cat /tmp/failure_analysis.json | python -c "import sys, json; data=json.load(sys.stdin); print('**Error Type:** ' + data.get('error_type', 'Unknown') + '\n**Root Cause:** ' + data.get('root_cause', 'Not identified') + '\n**Fix Confidence:** ' + str(data.get('fix_confidence', 0)) + '%')")
          
          # Create comprehensive issue with logs
          cat > /tmp/issue_body.md << 'ISSUE_EOF'
          # Workflow Failure: ${{ steps.get_run_details.outputs.workflow_name }}
          
          ## Failure Information
          
          - **Workflow**: ${{ steps.get_run_details.outputs.workflow_name }}
          - **Run ID**: [${{ steps.get_run_details.outputs.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ steps.get_run_details.outputs.run_id }})
          - **Branch**: ${{ steps.get_run_details.outputs.head_branch }}
          - **SHA**: ${{ steps.get_run_details.outputs.head_sha }}
          
          ## Analysis
          
          ISSUE_EOF
          
          echo "$ANALYSIS" >> /tmp/issue_body.md
          
          cat >> /tmp/issue_body.md << 'ISSUE_EOF'
          
          ## Failure Logs Summary
          
          ISSUE_EOF
          
          # Add log summary
          if [ -f /tmp/workflow_logs/summary.txt ]; then
            cat /tmp/workflow_logs/summary.txt >> /tmp/issue_body.md
          fi
          
          cat >> /tmp/issue_body.md << 'ISSUE_EOF'
          
          ## Detailed Logs
          
          ISSUE_EOF
          
          # Add first 50 lines of first failed job log for context
          if [ -f /tmp/workflow_logs/job_*.log ]; then
            FIRST_LOG=$(ls /tmp/workflow_logs/job_*.log | head -1)
            echo "\`\`\`" >> /tmp/issue_body.md
            head -50 "$FIRST_LOG" >> /tmp/issue_body.md
            echo "\`\`\`" >> /tmp/issue_body.md
            echo "" >> /tmp/issue_body.md
            echo "*Full logs available in [workflow run](${{ steps.get_run_details.outputs.run_id }})*" >> /tmp/issue_body.md
          fi
          
          cat >> /tmp/issue_body.md << 'ISSUE_EOF'
          
          ## Recommendations
          
          ISSUE_EOF
          
          # Add recommendations from analysis
          python -c "
          import json
          with open('/tmp/failure_analysis.json') as f:
              data = json.load(f)
              for rec in data.get('recommendations', []):
                  print('- ' + rec)
          " >> /tmp/issue_body.md
          
          cat >> /tmp/issue_body.md << 'ISSUE_EOF'
          
          ## Proposed Fix
          
          ISSUE_EOF
          
          # Add fix details from proposal
          python -c "
          import json
          with open('/tmp/fix_proposal.json') as f:
              data = json.load(f)
              for fix in data.get('fixes', []):
                  print(f\"### {fix.get('description', 'Fix')}\\n\")
                  print(f\"**File:** \\\`{fix.get('file', 'N/A')}\\\`\\n\")
                  print(f\"**Action:** {fix.get('action', 'N/A')}\\n\")
                  if fix.get('changes'):
                      print(f\"\\n\\\`\\\`\\\`yaml\\n{fix['changes']}\\n\\\`\\\`\\\`\\n\")
          " >> /tmp/issue_body.md
          
          cat >> /tmp/issue_body.md << 'ISSUE_EOF'
          
          ---
          
          🤖 This issue was created by the Auto-Healing System.
          GitHub Copilot has been assigned and will automatically create a pull request to fix this issue.
          ISSUE_EOF
          
          # Create the issue
          ISSUE_URL=$(gh issue create \
            --title "Fix workflow failure: ${{ steps.get_run_details.outputs.workflow_name }} (Run ${{ steps.get_run_details.outputs.run_id }})" \
            --body-file /tmp/issue_body.md \
            --label "automated,workflow-failure,auto-healing" \
            --assignee "Copilot")
          
          ISSUE_NUMBER=$(echo "$ISSUE_URL" | grep -oP '\d+$')
          
          echo "issue_url=$ISSUE_URL" >> $GITHUB_OUTPUT
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 📝 Issue Created and Assigned to Copilot" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "🔗 **Issue URL**: $ISSUE_URL" >> $GITHUB_STEP_SUMMARY
          echo "🔢 **Issue Number**: #$ISSUE_NUMBER" >> $GITHUB_STEP_SUMMARY
          echo "🤖 **Assigned to**: Copilot (Coding Agent will start automatically)" >> $GITHUB_STEP_SUMMARY
      
      - name: Wait for Copilot to create PR
        if: steps.create_issue.outputs.issue_number != ''
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ISSUE_NUMBER="${{ steps.create_issue.outputs.issue_number }}"
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ⏳ Waiting for GitHub Copilot Coding Agent" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The GitHub Copilot Coding Agent has been triggered by assigning issue #${ISSUE_NUMBER}." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### What happens next:" >> $GITHUB_STEP_SUMMARY
          echo "1. 🤖 Copilot analyzes the issue and repository context" >> $GITHUB_STEP_SUMMARY
          echo "2. 🔧 Creates a branch and implements the fix automatically" >> $GITHUB_STEP_SUMMARY
          echo "3. 📝 Opens a draft PR with the changes" >> $GITHUB_STEP_SUMMARY
          echo "4. 🔍 You review and approve the PR when ready" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Note**: The Copilot agent works asynchronously. Check issue #${ISSUE_NUMBER} for updates." >> $GITHUB_STEP_SUMMARY
      
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: copilot-autofix-${{ steps.get_run_details.outputs.run_id }}
          path: |
            /tmp/workflow_logs/
            /tmp/failure_analysis.json
            /tmp/fix_proposal.json
            /tmp/issue_body.md
          retention-days: 30
      
      - name: Report status
        if: always()
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.check_duplicate.outputs.should_skip }}" = "true" ]; then
            echo "### ⏭️ Workflow Skipped" >> $GITHUB_STEP_SUMMARY
            echo "- 🔍 Reason: ${{ steps.check_duplicate.outputs.skip_reason }}" >> $GITHUB_STEP_SUMMARY
            
            if [ "${{ steps.check_duplicate.outputs.skip_reason }}" = "no_run_id" ]; then
              echo "- ℹ️  No workflow run ID was found to analyze" >> $GITHUB_STEP_SUMMARY
            elif [ "${{ steps.check_duplicate.outputs.skip_reason }}" = "already_processed" ]; then
              echo "- ℹ️  This failure has already been analyzed and has fix PR(s)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "### 🤖 Auto-Healing Status" >> $GITHUB_STEP_SUMMARY
            echo "- ⚙️ Run ID: ${{ steps.get_run_details.outputs.run_id }}" >> $GITHUB_STEP_SUMMARY
            echo "- 📊 Analysis: ${{ steps.analyze_failure.outputs.analysis_available }}" >> $GITHUB_STEP_SUMMARY
            echo "- 🔧 Fix Generated: ${{ steps.generate_fix.outputs.fix_available }}" >> $GITHUB_STEP_SUMMARY
            echo "- 📝 Issue Created: ${{ steps.create_issue.outputs.issue_number != '' }}" >> $GITHUB_STEP_SUMMARY
            echo "- 🤖 Copilot Assigned: ${{ steps.create_issue.outputs.issue_number != '' }}" >> $GITHUB_STEP_SUMMARY
            
            if [ "${{ steps.create_issue.outputs.issue_number }}" != "" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "#### ✅ Success!" >> $GITHUB_STEP_SUMMARY
              echo "- Issue: #${{ steps.create_issue.outputs.issue_number }}" >> $GITHUB_STEP_SUMMARY
              echo "- Status: GitHub Copilot Coding Agent has been triggered" >> $GITHUB_STEP_SUMMARY
              echo "- Copilot will automatically create a draft PR with the fix" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**Monitor**: Check issue #${{ steps.create_issue.outputs.issue_number }} for Copilot's progress" >> $GITHUB_STEP_SUMMARY
            fi
          fi
