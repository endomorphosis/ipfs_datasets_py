# PDF Processing Pipeline CI/CD Workflow
#
# Purpose: Test PDF processing, GraphRAG integration, and MCP server endpoints
# Triggers: Push to main/develop, PRs, manual dispatch
# Duration: ~35-45 minutes
# Maintainer: Document processing team
# Dependencies: Python 3.12, PDF tools, GraphRAG, MCP server
# Related: graphrag-production-ci.yml, mcp-integration-tests.yml

name: PDF Processing Pipeline CI/CD

on:
  push:
    branches: [main, develop]
    paths:
      - 'ipfs_datasets_py/pdf_processing/**'
      - 'ipfs_datasets_py/mcp_server/tools/pdf_tools/**' 
      - 'tests/**'
      - 'requirements.txt'
      - '.github/workflows/**'
  pull_request:
    branches: [main]
    paths:
      - 'ipfs_datasets_py/pdf_processing/**'
      - 'ipfs_datasets_py/mcp_server/tools/pdf_tools/**'
      - 'tests/**'
      - 'requirements.txt'

permissions:
  contents: read
  actions: read
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true



env:
  PYTHON_VERSION: '3.12'
  PYTEST_TIMEOUT: '300'  # 5 minutes

jobs:
  # Check if self-hosted runners are available
  check-runner:
    uses: ./.github/workflows/templates/check-runner-availability.yml
    with:
      runner_labels: "self-hosted,linux,x64"
      skip_if_unavailable: true

  lint-and-format:
    name: Code Quality Checks
    needs: [check-runner]
    if: ${{ needs.check-runner.outputs.should_run == 'true' }}
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 10
    container:
      image: python:3.12-slim
      options: --user root
    steps:
    - name: Fix permissions before checkout
      run: |
        # Fix any permission issues from previous runs
        if [ -d "$GITHUB_WORKSPACE/.git" ]; then
          chmod -R u+rwX "$GITHUB_WORKSPACE/.git" 2>/dev/null || true
          chown -R root:root "$GITHUB_WORKSPACE" 2>/dev/null || true
        fi
    
    - name: Install system dependencies
      run: |
        apt-get update
        apt-get install -y git curl
    
    - uses: actions/checkout@v5
      with:
        fetch-depth: 1
    - name: Setup GitHub CLI and P2P Cache
      id: gh_setup
      uses: nick-invision/retry@v3
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_REPOSITORY: ${{ github.repository }}
        ENABLE_P2P_CACHE: true
      with:
        timeout_minutes: 5
        max_attempts: 3
        retry_on: error
        command: |
          # Install gh CLI for API caching
          apt-get install -y ca-certificates gnupg
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | \
            dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg 2>/dev/null
          chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg
          echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | \
            tee /etc/apt/sources.list.d/github-cli.list > /dev/null
          apt-get update
          apt-get install -y gh
          
          # Authenticate
          echo "$GH_TOKEN" | gh auth login --with-token
          gh auth status
          
          # Check rate limit
          RATE_LIMIT=$(gh api rate_limit --jq '.resources.core.remaining' 2>/dev/null || echo "0")
          echo "GitHub API Rate Limit: $RATE_LIMIT remaining"
    
    - name: Install Python dependencies
      id: pip_install
      uses: nick-invision/retry@v3
      with:
        timeout_minutes: 10
        max_attempts: 3
        retry_on: error
        command: |
          python --version
          python -m pip install --upgrade pip
          pip install flake8 black isort mypy
          pip install -r requirements.txt
    
    - name: Run Black formatter check
      run: |
        black --check --diff ipfs_datasets_py/pdf_processing/
        black --check --diff ipfs_datasets_py/mcp_server/tools/pdf_tools/
        black --check --diff tests/
      continue-on-error: true  # Formatting is advisory for now
    
    - name: Run isort import sorting check
      run: |
        isort --check-only --diff ipfs_datasets_py/pdf_processing/
        isort --check-only --diff ipfs_datasets_py/mcp_server/tools/pdf_tools/
        isort --check-only --diff tests/
      continue-on-error: true  # Import sorting is advisory for now
    
    - name: Run flake8 linting
      run: |
        flake8 ipfs_datasets_py/pdf_processing/ --max-line-length=100 --extend-ignore=E203,W503
        flake8 ipfs_datasets_py/mcp_server/tools/pdf_tools/ --max-line-length=100 --extend-ignore=E203,W503
        flake8 tests/ --max-line-length=100 --extend-ignore=E203,W503
      continue-on-error: true  # Linting is advisory for now
    
    - name: Run mypy type checking
      run: |
        mypy ipfs_datasets_py/pdf_processing/ --ignore-missing-imports
        mypy ipfs_datasets_py/mcp_server/tools/pdf_tools/ --ignore-missing-imports
      continue-on-error: true  # Type checking is advisory for now

  unit-tests:
    name: Unit Tests
    needs: [check-runner]
    if: ${{ needs.check-runner.outputs.should_run == 'true' }}
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 15
    container:
      image: python:3.12-slim
      options: --user root
    strategy:
      matrix:
        python-version: ['3.12']
        test-group: ['pdf-processing', 'mcp-tools', 'utils']
    
    steps:
    - name: Fix permissions before checkout
      run: |
        # Fix any permission issues from previous runs
        if [ -d "$GITHUB_WORKSPACE/.git" ]; then
          chmod -R u+rwX "$GITHUB_WORKSPACE/.git" 2>/dev/null || true
          chown -R root:root "$GITHUB_WORKSPACE" 2>/dev/null || true
        fi
    
    - name: Install system dependencies
      run: |
        apt-get update
        apt-get install -y git curl tesseract-ocr tesseract-ocr-eng
    
    - uses: actions/checkout@v5
      with:
      fetch-depth: 1    
    - name: Install Python dependencies
      run: |
        python --version
        python -m pip install --upgrade pip
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio pytest-timeout pytest-xdist
    
    - name: Run unit tests - PDF Processing
      if: matrix.test-group == 'pdf-processing'
      run: |
        pytest tests/unit/test_pdf_processor_unit.py \
          tests/unit/test_ocr_engine_unit.py \
          tests/unit/test_graphrag_integrator_unit.py \
          tests/unit/test_query_engine_unit.py \
          --cov=ipfs_datasets_py.pdf_processing \
          --cov-report=xml \
          --cov-report=term-missing \
          --timeout=${{ env.PYTEST_TIMEOUT }} \
          -v
    
    - name: Run unit tests - MCP Tools
      if: matrix.test-group == 'mcp-tools'
      run: |
        pytest tests/unit/test_mcp_pdf_tools.py \
          --cov=ipfs_datasets_py.mcp_server.tools.pdf_tools \
          --cov-report=xml \
          --cov-report=term-missing \
          --timeout=${{ env.PYTEST_TIMEOUT }} \
          -v
    
    - name: Run unit tests - Utils
      if: matrix.test-group == 'utils'
      run: |
        pytest tests/test_jsonnet_utils.py tests/test_import_utils.py \
          --cov=ipfs_datasets_py.utils \
          --cov-report=xml \
          --cov-report=term-missing \
          --timeout=${{ env.PYTEST_TIMEOUT }} \
          -v || {
          # Exit code 5 means no tests were collected/run (e.g., all skipped)
          # This is acceptable for optional test groups
          EXIT_CODE=$?
          if [ $EXIT_CODE -eq 5 ]; then
            echo "⚠️  No tests ran in utils test group (all tests may have been skipped due to missing optional dependencies)"
            echo "This is acceptable - utils tests require optional IPLD dependencies"
            exit 0
          else
            echo "❌ Tests failed with exit code $EXIT_CODE"
            exit $EXIT_CODE
          fi
        }
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  integration-tests:
    name: Integration Tests
    needs: [check-runner, unit-tests]
    if: ${{ needs.check-runner.outputs.should_run == 'true' }}
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 30
    container:
      image: python:3.12-slim
      options: --user root
    
    steps:
    - uses: actions/checkout@v5
      with:
        fetch-depth: 1    
    - name: Install system dependencies
      run: |
        apt-get update
        apt-get install -y tesseract-ocr tesseract-ocr-eng
    
    - name: Install Python dependencies
      run: |
        python --version
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-timeout
    
    - name: Run integration tests
      run: |
        pytest tests/integration/ \
          --timeout=${{ env.PYTEST_TIMEOUT }} \
          -v \
          --tb=short \
          --continue-on-collection-errors
      continue-on-error: true  # Some integration tests may require optional dependencies
    
    - name: Upload integration test artifacts
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: integration-test-artifacts
        path: |
          tests/fixtures/test_output/
          *.log

  mcp-server-tests:
    name: MCP Server Tests
    needs: [check-runner, unit-tests]
    if: ${{ needs.check-runner.outputs.should_run == 'true' }}
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 30
    container:
      image: python:3.12-slim
      options: --user root
    
    steps:
    - uses: actions/checkout@v5
      with:
        fetch-depth: 1    
    - name: Install dependencies
      run: |
        python --version
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-timeout
    
    - name: Run MCP server tests
      run: |
        pytest tests/mcp/ \
          --timeout=${{ env.PYTEST_TIMEOUT }} \
          -v \
          --tb=short
    
    - name: Test MCP tool registration
      run: |
        python -c "
        from ipfs_datasets_py.mcp_server.tools.pdf_tools import *
        print('✅ All MCP tools imported successfully')
        "
      continue-on-error: true  # Some tools may require optional dependencies

  performance-tests:
    name: Performance Tests
    needs: [check-runner, integration-tests]
    if: ${{ needs.check-runner.outputs.should_run == 'true' && github.ref == 'refs/heads/main' }}
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 30
    container:
      image: python:3.12-slim
      options: --user root
    
    steps:
    - uses: actions/checkout@v5
      with:
      fetch-depth: 1    
    - name: Install dependencies
      run: |
        python --version
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-benchmark memory_profiler
    
    - name: Run performance benchmarks
      run: |
        # Check if test file exists before running
        if [ -f "tests/integration/test_pdf_mcp_integration.py" ]; then
          python -m pytest tests/integration/test_pdf_mcp_integration.py::TestPerformanceIntegration \
            --benchmark-only \
            --benchmark-json=benchmark_results.json \
            -v || echo "⚠️  Performance tests failed or not available"
        else
          echo "Performance test file not found, skipping benchmarks"
          echo "Note: Create tests/integration/test_pdf_mcp_integration.py for performance testing"
        fi
      continue-on-error: true
    
    - name: Upload benchmark results
      if: always() && hashFiles('benchmark_results.json') != ''
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: benchmark_results.json
        if-no-files-found: warn

  security-scan:
    name: Security Scan
    needs: [check-runner]
    if: ${{ needs.check-runner.outputs.should_run == 'true' }}
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 20
    
    steps:
    - uses: actions/checkout@v5
      with:
        fetch-depth: 1    
    - name: Install security scanning tools
      run: |
        python --version
        python -m pip install --upgrade pip
        pip install bandit safety
    
    - name: Run Bandit security linter
      run: |
        bandit -r ipfs_datasets_py/pdf_processing/ \
          -f json -o bandit_report.json
        bandit -r ipfs_datasets_py/mcp_server/tools/pdf_tools/ \
          -f json -o bandit_mcp_report.json
      continue-on-error: true
    
    - name: Run Safety dependency check
      run: |
        safety check --json --output safety_report.json
      continue-on-error: true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          bandit_report.json
          bandit_mcp_report.json
          safety_report.json

  docker-tests:
    name: Docker Tests
    needs: [check-runner, integration-tests]
    if: ${{ needs.check-runner.outputs.should_run == 'true' }}
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 30
    
    steps:
    - uses: actions/checkout@v5
      with:
        fetch-depth: 1    
    - name: Build Docker image
      run: |
        docker build -t ipfs-datasets-pdf:test .
    
    - name: Test Docker container
      run: |
        docker run --rm \
          -v ${{ github.workspace }}/tests:/app/tests \
          ipfs-datasets-pdf:test \
          python -m pytest tests/unit/test_pdf_processor_unit.py::TestPDFProcessorInitialization::test_given_no_parameters_when_initializing_pdf_processor_then_creates_with_defaults -v
    
    - name: Test MCP tools in container
      run: |
        docker run --rm \
          ipfs-datasets-pdf:test \
          python -c "
          from ipfs_datasets_py.pdf_processing import PDFProcessor
          from ipfs_datasets_py.mcp_server.tools.pdf_tools import pdf_ingest_to_graphrag
          print('✅ PDF processing and MCP tools work in Docker')
          "

  deployment-tests:
    name: Deployment Tests
    needs: [check-runner, integration-tests, mcp-server-tests]
    if: ${{ needs.check-runner.outputs.should_run == 'true' && github.ref == 'refs/heads/main' }}
    runs-on: [self-hosted, linux, x64]
    timeout-minutes: 30
    
    steps:
    - uses: actions/checkout@v5
      with:
        fetch-depth: 1    
    - name: Test package installation
      run: |
        python --version
        python -m pip install --upgrade pip
        # First test base package installation
        pip install -e .
        python -c "import ipfs_datasets_py; print('✅ Base package imports correctly')"
        
        # Try importing PDF processing with proper error handling
        python -c "
        import ipfs_datasets_py
        from ipfs_datasets_py import pdf_processing
        
        # Check if PDFProcessor is available (may not be if optional deps missing)
        if hasattr(pdf_processing, 'HAVE_PDF_PROCESSOR'):
            if pdf_processing.HAVE_PDF_PROCESSOR:
                from ipfs_datasets_py.pdf_processing import PDFProcessor
                print('✅ PDFProcessor available with all dependencies')
            else:
                print('ℹ️  PDFProcessor not available - optional dependencies needed')
                print('   Install with: pip install -e .[all]')
        
        # Always print this regardless of PDF processor availability
        print('✅ Package structure is valid')
        " || echo "⚠️  Some optional components require additional dependencies"
    
    - name: Test package with extras installation
      run: |
        pip install -r requirements.txt
        python -c "
        import ipfs_datasets_py
        # Try importing PDF processing components - will use mock if dependencies unavailable
        try:
            from ipfs_datasets_py import pdf_processing
            print('✅ PDF processing module available')
        except Exception as e:
            print(f'⚠️  PDF processing module using limited functionality: {e}')
        print('✅ Package with requirements installs correctly')
        "
      continue-on-error: true
    
    - name: Test CLI functionality
      run: |
        # Test any CLI commands if they exist
        python -m ipfs_datasets_py.pdf_processing --help || true
    
    - name: Run quick smoke tests
      run: |
        python archive/experiments/pdf_processing_quick_test.py || echo "Quick test not available, skipping"
      continue-on-error: true

  notify-status:
    name: Notify Status
    needs: [check-runner, lint-and-format, unit-tests, integration-tests, mcp-server-tests]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Notify success
      if: ${{ needs.lint-and-format.result == 'success' && needs.unit-tests.result == 'success' && needs.integration-tests.result == 'success' && needs.mcp-server-tests.result == 'success' }}
      run: |
        echo "✅ All tests passed successfully!"
        echo "PDF processing pipeline and MCP tools are ready for deployment."
    
    - name: Notify failure
      if: ${{ needs.lint-and-format.result == 'failure' || needs.unit-tests.result == 'failure' || needs.integration-tests.result == 'failure' || needs.mcp-server-tests.result == 'failure' }}
      run: |
        echo "❌ Some tests failed. Please check the logs."
        exit 1
