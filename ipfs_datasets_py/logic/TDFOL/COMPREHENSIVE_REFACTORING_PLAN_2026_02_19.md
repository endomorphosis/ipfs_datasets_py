# TDFOL Comprehensive Refactoring and Improvement Plan
**Date:** 2026-02-19  
**Version:** 1.0  
**Status:** Planning Phase Complete

---

## Executive Summary

This document outlines a comprehensive refactoring and improvement plan for the TDFOL (Temporal Deontic First-Order Logic) module. The plan addresses:

1. **Critical Issue**: LLMResponseCache using sha256 instead of IPFS CIDs with multiformats
2. **Architecture**: Extract ProverStrategy interface, unify validation logic
3. **Testing**: Create comprehensive test suite (currently <20% coverage)
4. **Performance**: Optimize NL pipeline, consolidate visualization modules
5. **Quality**: Type system hardening, documentation consolidation

**Current State**: 18,400 LOC across 36 Python files, 60% production-ready  
**Target State**: 90%+ production-ready with 80%+ test coverage

---

## 1. Module Analysis

### 1.1 Current Structure

```
TDFOL/
â”œâ”€â”€ Core (3 files, 1,945 LOC)
â”‚   â”œâ”€â”€ tdfol_core.py          - AST definitions (551 LOC)
â”‚   â”œâ”€â”€ tdfol_parser.py        - Parser (564 LOC)
â”‚   â””â”€â”€ tdfol_prover.py        - Theorem prover (830 LOC)
â”‚
â”œâ”€â”€ Supporting (5 files, 3,416 LOC)
â”‚   â”œâ”€â”€ tdfol_inference_rules.py  - Rule library (1,892 LOC)
â”‚   â”œâ”€â”€ tdfol_optimization.py     - Performance (531 LOC)
â”‚   â”œâ”€â”€ tdfol_proof_cache.py      - Caching (92 LOC)
â”‚   â”œâ”€â”€ tdfol_converter.py        - Format conversion (528 LOC)
â”‚   â””â”€â”€ tdfol_dcec_parser.py      - DCEC integration (373 LOC)
â”‚
â”œâ”€â”€ Visualization (5 files, 3,968 LOC)
â”‚   â”œâ”€â”€ proof_tree_visualizer.py      - Proof trees (999 LOC)
â”‚   â”œâ”€â”€ formula_dependency_graph.py   - Dependencies (889 LOC)
â”‚   â”œâ”€â”€ countermodel_visualizer.py    - Countermodels (1,100 LOC)
â”‚   â”œâ”€â”€ countermodels.py              - Generation (403 LOC)
â”‚   â””â”€â”€ proof_explainer.py            - Explanations (577 LOC)
â”‚
â”œâ”€â”€ Performance & Security (3 files, 3,474 LOC)
â”‚   â”œâ”€â”€ performance_profiler.py   - Profiling (1,407 LOC)
â”‚   â”œâ”€â”€ performance_dashboard.py  - Metrics (1,314 LOC)
â”‚   â””â”€â”€ security_validator.py     - Validation (753 LOC)
â”‚
â”œâ”€â”€ Natural Language (6 files, 2,821 LOC)
â”‚   â”œâ”€â”€ nl/tdfol_nl_api.py          - API (294 LOC)
â”‚   â”œâ”€â”€ nl/tdfol_nl_preprocessor.py - Preprocessing (327 LOC)
â”‚   â”œâ”€â”€ nl/tdfol_nl_patterns.py     - Patterns (826 LOC)
â”‚   â”œâ”€â”€ nl/tdfol_nl_generator.py    - Generation (482 LOC)
â”‚   â”œâ”€â”€ nl/tdfol_nl_context.py      - Context (333 LOC)
â”‚   â””â”€â”€ nl/llm_nl_converter.py      - LLM integration (412 LOC) â† TARGET
â”‚
â”œâ”€â”€ P2P & Distributed (1 file, 346 LOC)
â”‚   â””â”€â”€ p2p/ipfs_proof_storage.py
â”‚
â””â”€â”€ Other (4 files, 2,430 LOC)
    â”œâ”€â”€ exceptions.py           - Error handling (684 LOC)
    â”œâ”€â”€ zkp_integration.py      - Zero-knowledge (633 LOC)
    â”œâ”€â”€ modal_tableaux.py       - Modal logic (610 LOC)
    â””â”€â”€ __init__.py

TOTAL: 36 files, ~18,400 LOC
```

### 1.2 Code Quality Metrics

| Metric | Current | Target | Priority |
|--------|---------|--------|----------|
| **Test Coverage** | <20% | 80%+ | Critical |
| **Type Coverage** | ~70% | 95%+ | High |
| **Complexity (avg)** | 15-20 | <10 | High |
| **Duplication** | ~15% | <5% | Medium |
| **Documentation** | 60% | 90%+ | Low |

### 1.3 Key Issues Identified

**Critical:**
1. âŒ **LLMResponseCache uses sha256 instead of IPFS CIDs** (security/compatibility)
2. âŒ **No comprehensive test suite** (<20% coverage, no pytest for core modules)
3. âŒ **High complexity in tdfol_prover.py** (830 LOC, handles 4+ concerns)

**High Priority:**
4. âš ï¸ **No ProverStrategy interface** (ad-hoc strategy selection)
5. âš ï¸ **Validation logic scattered** (parser, security_validator, exceptions)
6. âš ï¸ **NL pipeline overhead** (2-3s latency, tries both pattern + LLM sequentially)

**Medium Priority:**
7. âš ï¸ **Visualization module bloat** (2,502 LOC across 3 files)
8. âš ï¸ **Hardcoded configuration** (max_formula_size, max_proof_time)
9. âš ï¸ **Type hints incomplete** (20+ uses of `Any` in zkp_integration.py)

---

## 2. Phase 1: LLMResponseCache IPFS CID Migration

### 2.1 Problem Statement

**Current Implementation** (`llm_nl_converter.py:72-75`):
```python
def _make_key(self, text: str, provider: str, prompt_hash: str) -> str:
    """Create cache key from text and parameters."""
    combined = f"{text}|{provider}|{prompt_hash}"
    return hashlib.sha256(combined.encode()).hexdigest()
```

**Issues:**
- Uses standard sha256 hash (not IPFS-compatible)
- Not content-addressed (uses arbitrary string concatenation)
- Cannot be verified or retrieved from IPFS network
- Incompatible with distributed caching strategy

### 2.2 Solution Design

**New Implementation** using multiformats:
```python
from multiformats import CID, multihash

def _make_key(self, text: str, provider: str, prompt_hash: str) -> str:
    """Create IPFS CID cache key using multiformats."""
    # Create deterministic JSON structure
    cache_obj = {
        "text": text,
        "provider": provider,
        "prompt_hash": prompt_hash,
        "version": "1.0"  # For future schema evolution
    }
    
    # Serialize to canonical JSON bytes
    json_bytes = json.dumps(
        cache_obj,
        sort_keys=True,
        separators=(",", ":"),
        ensure_ascii=False
    ).encode("utf-8")
    
    # Generate multihash
    mh = multihash.digest(json_bytes, "sha2-256")
    
    # Create CIDv1
    cid = CID("base32", 1, "raw", mh)
    
    return str(cid)
```

**Benefits:**
- âœ… Content-addressed (same inputs â†’ same CID)
- âœ… IPFS-native format (can be stored/retrieved from IPFS)
- âœ… Verifiable (CID contains hash algorithm info)
- âœ… Future-proof (supports schema versioning)
- âœ… Interoperable with other IPFS tools

### 2.3 Implementation Plan

**Step 1: Add utility function** (15 min)
```python
# New file: ipfs_datasets_py/logic/TDFOL/nl/cache_utils.py
from multiformats import CID, multihash
import json
from typing import Dict, Any

def create_cache_cid(data: Dict[str, Any]) -> str:
    """Create IPFS CID for cache key using multiformats."""
    json_bytes = json.dumps(
        data, 
        sort_keys=True, 
        separators=(",", ":"),
        ensure_ascii=False
    ).encode("utf-8")
    
    mh = multihash.digest(json_bytes, "sha2-256")
    cid = CID("base32", 1, "raw", mh)
    return str(cid)
```

**Step 2: Update LLMResponseCache** (20 min)
- Import `create_cache_cid` utility
- Replace `_make_key()` implementation
- Update docstrings to mention IPFS CID format
- Add backward compatibility check (optional)

**Step 3: Update tests** (30 min)
- Update `test_llm_nl_converter.py` to validate CID format
- Add test for CID determinism (same inputs â†’ same CID)
- Add test for CID structure (version, codec, hash type)
- Verify cache still works with new format

**Step 4: Update documentation** (15 min)
- Update `llm_nl_converter.py` docstring
- Add migration note for existing deployments
- Document CID format in README

**Total Effort: 1.5 hours**

### 2.4 Backward Compatibility

**Option A: Hard Migration** (Recommended)
- Clear old cache on upgrade
- Simple, clean implementation
- Acceptable since cache is transient

**Option B: Dual Support**
- Check if key starts with "bafk" (CIDv1 base32)
- If not, try as legacy sha256 key
- Gradually migrate entries

**Recommendation:** Option A (hard migration) - LLM cache is performance optimization, not persistent data.

### 2.5 Testing Strategy

**Unit Tests:**
```python
def test_cache_key_is_ipfs_cid():
    """Verify cache keys are valid IPFS CIDs."""
    cache = LLMResponseCache()
    key = cache._make_key("test", "openai", "hash1")
    
    # Should be CIDv1 (starts with 'bafk' in base32)
    assert key.startswith("bafk")
    assert len(key) > 50  # CIDs are longer than sha256 hex
    
    # Should be parseable as CID
    from multiformats import CID
    cid = CID.decode(key)
    assert cid.version == 1
    assert cid.codec == "raw"

def test_cache_key_determinism():
    """Verify same inputs produce same CID."""
    cache = LLMResponseCache()
    key1 = cache._make_key("test", "openai", "hash1")
    key2 = cache._make_key("test", "openai", "hash1")
    assert key1 == key2

def test_cache_key_uniqueness():
    """Verify different inputs produce different CIDs."""
    cache = LLMResponseCache()
    key1 = cache._make_key("test1", "openai", "hash1")
    key2 = cache._make_key("test2", "openai", "hash1")
    assert key1 != key2
```

**Integration Tests:**
```python
def test_cache_operations_with_cid():
    """Verify cache still works with CID keys."""
    cache = LLMResponseCache(max_size=10)
    
    # Store and retrieve
    cache.put("text", "openai", "hash", "formula", 0.9)
    result = cache.get("text", "openai", "hash")
    
    assert result is not None
    assert result[0] == "formula"
    assert result[1] == 0.9
```

---

## 3. Phase 2: Core Refactoring

### 3.1 Extract ProverStrategy Interface

**Problem:** `tdfol_prover.py` (830 LOC) handles multiple concerns:
- Forward chaining
- Backward chaining
- Timeout management
- CEC integration
- Modal tableaux

**Solution:** Extract strategy interface

```python
# New file: ipfs_datasets_py/logic/TDFOL/strategies/base.py
from abc import ABC, abstractmethod
from typing import Optional, List
from ..tdfol_core import Formula, TDFOLKnowledgeBase

class ProverStrategy(ABC):
    """Abstract base class for proving strategies."""
    
    @abstractmethod
    def can_handle(self, formula: Formula, kb: TDFOLKnowledgeBase) -> bool:
        """Check if this strategy can handle the given formula."""
        pass
    
    @abstractmethod
    def prove(
        self, 
        formula: Formula, 
        kb: TDFOLKnowledgeBase,
        timeout: Optional[float] = None
    ) -> ProofResult:
        """Attempt to prove the formula."""
        pass
    
    @abstractmethod
    def get_priority(self) -> int:
        """Get strategy priority (higher = try first)."""
        pass
```

**Implementations:**
1. `ForwardChainingStrategy` - Standard forward chaining
2. `BackwardChainingStrategy` - Goal-directed proving
3. `BidirectionalStrategy` - Meet-in-the-middle
4. `ModalTableauxStrategy` - For modal formulas
5. `CECDelegateStrategy` - Delegates to CEC prover

**Benefits:**
- âœ… Reduce `tdfol_prover.py` from 830 â†’ 300 LOC
- âœ… Enable pluggable strategies
- âœ… Easier testing (test each strategy independently)
- âœ… Better maintainability

**Effort:** 2-3 days

### 3.2 Unify Formula Validation

**Problem:** Validation scattered across:
- `tdfol_parser.py` - Syntax validation
- `security_validator.py` - Security checks
- `exceptions.py` - Error handling

**Solution:** Create `FormulaValidator` class

```python
# New file: ipfs_datasets_py/logic/TDFOL/validation/validator.py
from dataclasses import dataclass
from typing import List, Optional
from ..tdfol_core import Formula

@dataclass
class ValidationResult:
    """Result of formula validation."""
    valid: bool
    errors: List[str]
    warnings: List[str]
    security_issues: List[str]

class FormulaValidator:
    """Unified formula validation."""
    
    def __init__(self, max_size: int = 10000, max_depth: int = 100):
        self.max_size = max_size
        self.max_depth = max_depth
    
    def validate(self, formula: Formula) -> ValidationResult:
        """Validate formula (syntax, security, complexity)."""
        errors = []
        warnings = []
        security_issues = []
        
        # Size checks
        formula_str = str(formula)
        if len(formula_str) > self.max_size:
            errors.append(f"Formula too large: {len(formula_str)} > {self.max_size}")
        
        # Depth checks
        depth = self._compute_depth(formula)
        if depth > self.max_depth:
            errors.append(f"Formula too deep: {depth} > {self.max_depth}")
        
        # Security checks
        security_issues.extend(self._check_security(formula))
        
        return ValidationResult(
            valid=len(errors) == 0 and len(security_issues) == 0,
            errors=errors,
            warnings=warnings,
            security_issues=security_issues
        )
```

**Effort:** 2-3 days

### 3.3 Create Comprehensive Test Suite

**Current State:** <20% coverage, no systematic testing

**Target:** 80%+ coverage across all modules

**Test Organization:**
```
tests/unit_tests/logic/TDFOL/
â”œâ”€â”€ test_tdfol_core.py              (50 tests) âœ… EXISTS
â”œâ”€â”€ test_tdfol_parser.py            (100 tests) - EXPAND
â”œâ”€â”€ test_tdfol_prover.py            (150 tests) - EXPAND
â”œâ”€â”€ test_tdfol_inference_rules.py   (80 tests) - NEW
â”œâ”€â”€ test_tdfol_optimization.py      (40 tests) - NEW
â”œâ”€â”€ nl/
â”‚   â”œâ”€â”€ test_tdfol_nl_api.py        (30 tests) âœ… EXISTS
â”‚   â”œâ”€â”€ test_tdfol_nl_patterns.py   (50 tests) - NEW
â”‚   â””â”€â”€ test_llm_nl_converter.py    (40 tests) âœ… EXISTS
â”œâ”€â”€ strategies/
â”‚   â”œâ”€â”€ test_forward_chaining.py    (30 tests) - NEW
â”‚   â”œâ”€â”€ test_backward_chaining.py   (30 tests) - NEW
â”‚   â””â”€â”€ test_modal_tableaux.py      (25 tests) âœ… EXISTS
â””â”€â”€ validation/
    â””â”€â”€ test_validator.py            (50 tests) - NEW

TOTAL: 675+ tests (currently ~100)
```

**Test Categories:**

1. **Parser Tests** (100 tests)
   - Valid formula parsing (40 tests)
   - Error handling (30 tests)
   - Edge cases (20 tests)
   - Fuzz testing (10 tests)

2. **Prover Tests** (150 tests)
   - Basic theorems (50 tests)
   - Temporal logic (30 tests)
   - Deontic logic (30 tests)
   - Modal logic (20 tests)
   - Performance (20 tests)

3. **NL Tests** (120 tests)
   - Pattern matching (50 tests)
   - LLM integration (40 tests)
   - Context tracking (30 tests)

**Effort:** 5-7 days

---

## 4. Phase 3: Optimization

### 4.1 Consolidate Visualization Modules

**Current:** 3 visualization files, 2,502 LOC

**Problem:** Duplication in:
- ASCII rendering (3 implementations)
- HTML generation (3 implementations)
- SVG generation (2 implementations)

**Solution:** Extract common rendering logic

```python
# New file: ipfs_datasets_py/logic/TDFOL/visualization/renderers.py
from abc import ABC, abstractmethod

class Renderer(ABC):
    """Abstract base class for renderers."""
    
    @abstractmethod
    def render(self, data: Any) -> str:
        pass

class ASCIIRenderer(Renderer):
    """ASCII text rendering."""
    def render(self, data: Any) -> str:
        # Shared ASCII rendering logic
        pass

class HTMLRenderer(Renderer):
    """HTML rendering with templates."""
    def render(self, data: Any) -> str:
        # Shared HTML rendering logic
        pass

class SVGRenderer(Renderer):
    """SVG vector graphics rendering."""
    def render(self, data: Any) -> str:
        # Shared SVG rendering logic
        pass
```

**Expected Reduction:** 2,502 â†’ 1,200 LOC (52% reduction)

**Effort:** 2 days

### 4.2 Optimize NL Pipeline

**Current Performance:**
- Pattern matching: ~500ms
- LLM call: ~1.5-2s
- Total: ~2-3s (sequential execution)

**Target Performance:** <200ms for 80% of inputs

**Optimizations:**

1. **Parallel Pattern Matching**
   ```python
   # Run multiple patterns in parallel
   with ThreadPoolExecutor(max_workers=5) as executor:
       futures = [executor.submit(pattern.match, text) for pattern in patterns]
       results = [f.result() for f in futures]
   ```

2. **Smart LLM Skipping**
   ```python
   # Skip LLM if pattern confidence > threshold
   if pattern_result.confidence >= 0.85:
       return pattern_result  # No LLM needed
   ```

3. **Response Caching with IPFS CIDs** âœ… (Already planned in Phase 1)

4. **Batch Processing**
   ```python
   # Process multiple sentences in one LLM call
   batch_results = llm.generate_batch(sentences)
   ```

**Expected Improvement:**
- 80% of inputs: 2-3s â†’ 200ms (15x faster)
- 20% of inputs: 2-3s â†’ 1.5s (LLM still needed)

**Effort:** 1-2 days

### 4.3 Configuration Management

**Problem:** Hardcoded values in multiple files:
```python
max_formula_size = 10000  # In tdfol_parser.py
max_proof_time = 30.0     # In tdfol_prover.py
max_depth = 100           # In security_validator.py
cache_size = 1000         # In llm_nl_converter.py
```

**Solution:** Centralized configuration

```python
# New file: ipfs_datasets_py/logic/TDFOL/config.py
from dataclasses import dataclass
import os

@dataclass
class TDFOLConfig:
    """Centralized TDFOL configuration."""
    
    # Parser limits
    max_formula_size: int = 10000
    max_parse_depth: int = 100
    
    # Prover settings
    max_proof_time: float = 30.0
    max_proof_steps: int = 10000
    default_strategy: str = "auto"
    
    # Cache settings
    cache_size: int = 1000
    enable_ipfs_cache: bool = True
    
    # Security settings
    enable_validation: bool = True
    max_nested_depth: int = 50
    
    @classmethod
    def from_env(cls) -> "TDFOLConfig":
        """Load config from environment variables."""
        return cls(
            max_formula_size=int(os.getenv("TDFOL_MAX_FORMULA_SIZE", "10000")),
            max_proof_time=float(os.getenv("TDFOL_MAX_PROOF_TIME", "30.0")),
            # ... etc
        )

# Global config instance
config = TDFOLConfig.from_env()
```

**Effort:** 1-2 days

---

## 5. Phase 4: Type System Hardening

### 5.1 Current Type Coverage

**Files with incomplete typing:**
- `zkp_integration.py` - 20+ uses of `Any`
- `tdfol_optimization.py` - 15 uses of `Any`
- `performance_dashboard.py` - 10 uses of `Any`

### 5.2 Improvements

1. **Replace `Any` with specific types**
   ```python
   # Before
   def process(data: Any) -> Any:
       ...
   
   # After
   from typing import Union, Dict, List
   def process(data: Union[Formula, str]) -> Dict[str, List[str]]:
       ...
   ```

2. **Add `@overload` for polymorphic functions**
   ```python
   from typing import overload
   
   @overload
   def parse(text: str) -> Formula: ...
   
   @overload
   def parse(text: str, options: ParseOptions) -> ParseResult: ...
   
   def parse(text: str, options: Optional[ParseOptions] = None):
       ...
   ```

3. **Use TypedDict for dictionaries**
   ```python
   from typing import TypedDict
   
   class ProofResult(TypedDict):
       success: bool
       formula: Formula
       steps: List[ProofStep]
       time_ms: float
   ```

**Target:** 95%+ type coverage, 0 mypy errors

**Effort:** 3-4 days

---

## 6. Phase 5: Documentation Consolidation

### 6.1 Current State

**Documentation Files in Source Tree** (should be moved):
```
TDFOL/
â”œâ”€â”€ COMPREHENSIVE_REFACTORING_IMPROVEMENT_PLAN.md
â”œâ”€â”€ FORMULA_DEPENDENCY_GRAPH.md
â”œâ”€â”€ IMPLEMENTATION_QUICK_START_2026.md
â”œâ”€â”€ PHASE7_COMPLETION_REPORT.md
â”œâ”€â”€ PHASE8_COMPLETION_REPORT.md
â”œâ”€â”€ PHASE9_COMPLETE_SUMMARY.md
â”œâ”€â”€ PHASE_13_WEEK_1_COMPLETE.md
â”œâ”€â”€ REFACTORING_EXECUTIVE_SUMMARY.md
â”œâ”€â”€ REFACTORING_EXECUTIVE_SUMMARY_2026.md
â”œâ”€â”€ REFACTORING_PLAN_2026_02_18.md
â”œâ”€â”€ STATUS_2026.md
â”œâ”€â”€ TASK_11.2_COMPLETE.md
â”œâ”€â”€ UNIFIED_REFACTORING_ROADMAP_2026.md
â”œâ”€â”€ ZKP_INTEGRATION_STRATEGY.md
... (30+ markdown files)
```

### 6.2 Consolidation Plan

**Move to docs/:**
```
docs/logic/TDFOL/
â”œâ”€â”€ ARCHITECTURE.md          (Consolidate 5 architecture docs)
â”œâ”€â”€ ROADMAP.md               (Consolidate 10 planning docs)
â”œâ”€â”€ CHANGELOG.md             (Consolidate phase reports)
â”œâ”€â”€ API_REFERENCE.md         (Generate from docstrings)
â””â”€â”€ DEVELOPER_GUIDE.md       (Quick start + examples)
```

**Keep in Source:**
- README.md (overview + quick start)
- Individual component READMEs (e.g., proof_tree_visualizer_README.md)

**Effort:** 2 days

---

## 7. Implementation Timeline

### Week 1: Critical Fixes
- **Day 1-2:** LLMResponseCache IPFS CID migration âœ…
- **Day 3-5:** Begin ProverStrategy extraction
- **Day 5:** Initial test suite setup

### Week 2: Core Refactoring
- **Day 1-3:** Complete ProverStrategy extraction
- **Day 4-5:** Unify Formula Validation

### Week 3: Testing
- **Day 1-5:** Implement comprehensive test suite (300+ tests)

### Week 4: Optimization
- **Day 1-2:** Consolidate visualization modules
- **Day 3:** Optimize NL pipeline
- **Day 4-5:** Configuration management + documentation

### Week 5: Polish
- **Day 1-3:** Type system hardening
- **Day 4-5:** Documentation consolidation + final review

**Total Effort:** ~20-25 days (1 person) or 4-5 weeks

---

## 8. Success Metrics

| Metric | Current | Target | Status |
|--------|---------|--------|--------|
| **Test Coverage** | <20% | 80%+ | ðŸŽ¯ |
| **Type Coverage** | ~70% | 95%+ | ðŸŽ¯ |
| **LOC (Core)** | 1,945 | 1,800 | ðŸ“‰ |
| **LOC (Visualization)** | 2,502 | 1,200 | ðŸ“‰ |
| **Avg Complexity** | 15-20 | <10 | ðŸ“‰ |
| **NL Latency (80%)** | 2-3s | <200ms | ðŸ“‰ |
| **Production Ready** | 60% | 90%+ | ðŸŽ¯ |

---

## 9. Risk Mitigation

### 9.1 Risks

1. **Breaking Changes** - Refactoring may break existing code
   - **Mitigation:** Comprehensive test suite before refactoring
   - **Mitigation:** Feature flags for gradual rollout

2. **Performance Regression** - New abstractions may slow down code
   - **Mitigation:** Benchmark before/after
   - **Mitigation:** Profile hot paths

3. **Schedule Slip** - Scope creep or underestimation
   - **Mitigation:** Prioritize critical fixes first
   - **Mitigation:** Time-box each phase

### 9.2 Rollback Plan

- Keep feature branches for each phase
- Tag releases before major refactoring
- Document migration guides
- Maintain backward compatibility where possible

---

## 10. Appendices

### A. Code Examples

See inline code examples throughout the document.

### B. Dependencies

**Required:**
- `multiformats` (for CID generation)
- `pytest` (for testing)
- `mypy` (for type checking)

**Optional:**
- `hypothesis` (for property-based testing)
- `pytest-cov` (for coverage reports)
- `pytest-benchmark` (for performance testing)

### C. References

- IPFS CID Specification: https://github.com/multiformats/cid
- Multiformats: https://multiformats.io/
- TDFOL Documentation: `ipfs_datasets_py/logic/TDFOL/README.md`

---

**End of Document**
