"""
Test Generator Engine — canonical business logic for generating test files.

This module contains the domain logic for Jinja2-based test generation and
is the single source of truth used by:
- MCP server tool: ``mcp_server/tools/development_tools/test_generator.py``
- CLI command: ``ipfs-datasets test_generator …``
- Direct Python import: ``from ipfs_datasets_py.processors.development import TestGeneratorCore``
"""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

try:
    import jinja2
    JINJA2_AVAILABLE = True
except ImportError:
    JINJA2_AVAILABLE = False
    jinja2 = None  # type: ignore[assignment]

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Exceptions
# ---------------------------------------------------------------------------


class TestGeneratorError(Exception):
    """Base error for the test generator engine."""


class TestGeneratorValidationError(TestGeneratorError):
    """Raised when an input specification fails validation."""


class TestGeneratorExecutionError(TestGeneratorError):
    """Raised when test content generation fails."""


# ---------------------------------------------------------------------------
# Configuration dataclass
# ---------------------------------------------------------------------------


@dataclass
class TestGeneratorConfig:
    """Configuration for the test generator engine."""

    output_dir: str = "tests"
    harness: str = "unittest"  # "unittest" or "pytest"
    default_fixtures: bool = False
    parametrized: bool = False
    docstring_style: str = "google"
    debug: bool = False


# ---------------------------------------------------------------------------
# Jinja2 templates (module-level constants)
# ---------------------------------------------------------------------------

UNITTEST_TEMPLATE: str = '''"""
{{ description }}

Generated by IPFS Datasets Test Generator
Date: {{ timestamp }}
Test Framework: unittest
"""

import unittest
{% if imports %}
{% for import in imports %}
{{ import }}
{% endfor %}
{% endif %}
from pathlib import Path
import sys

# Add project root to Python path
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

{% if dataset_imports %}
# Dataset-specific imports
{% for import in dataset_imports %}
{{ import }}
{% endfor %}
{% endif %}


class {{ class_name }}(unittest.TestCase):
    """{{ description }}"""

    {% if fixtures %}
    def setUp(self):
        """Set up test fixtures."""
        {% for fixture in fixtures %}
        self.{{ fixture.name }} = {{ fixture.value }}
        {% endfor %}
        {% if dataset_fixtures %}
        # Dataset fixtures
        {% for fixture in dataset_fixtures %}
        self.{{ fixture.name }} = {{ fixture.value }}
        {% endfor %}
        {% endif %}

    def tearDown(self):
        """Clean up after tests."""
        pass

    {% endif %}
    {% for test in tests %}
    def test_{{ test.name }}(self):
        """{{ test.description }}"""
        {% if test.setup %}
        # Test setup
        {% for setup_line in test.setup %}
        {{ setup_line }}
        {% endfor %}
        {% endif %}

        {% if test.is_dataset_test %}
        # Dataset-specific test logic
        {% if test.dataset_operations %}
        {% for operation in test.dataset_operations %}
        {{ operation }}
        {% endfor %}
        {% endif %}
        {% endif %}

        # Test execution
        {% if test.parametrized %}
        test_cases = {{ test.test_cases }}
        for case in test_cases:
            with self.subTest(case=case):
                {% for assertion in test.assertions %}
                {{ assertion.replace('case', 'case') }}
                {% endfor %}
        {% else %}
        {% for assertion in test.assertions %}
        {{ assertion }}
        {% endfor %}
        {% endif %}

        {% if test.cleanup %}
        # Test cleanup
        {% for cleanup_line in test.cleanup %}
        {{ cleanup_line }}
        {% endfor %}
        {% endif %}

    {% endfor %}

if __name__ == '__main__':
    unittest.main()
'''

PYTEST_TEMPLATE: str = '''"""
{{ description }}

Generated by IPFS Datasets Test Generator
Date: {{ timestamp }}
Test Framework: pytest
"""

import pytest
{% if imports %}
{% for import in imports %}
{{ import }}
{% endfor %}
{% endif %}
from pathlib import Path
import sys

# Add project root to Python path
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

{% if dataset_imports %}
# Dataset-specific imports
{% for import in dataset_imports %}
{{ import }}
{% endfor %}
{% endif %}

{% if fixtures %}
# Test fixtures
{% for fixture in fixtures %}
@pytest.fixture
def {{ fixture.name }}():
    """{{ fixture.description or 'Test fixture' }}"""
    return {{ fixture.value }}

{% endfor %}
{% endif %}

{% if dataset_fixtures %}
# Dataset fixtures
{% for fixture in dataset_fixtures %}
@pytest.fixture
def {{ fixture.name }}():
    """{{ fixture.description or 'Dataset fixture' }}"""
    return {{ fixture.value }}

{% endfor %}
{% endif %}

{% for test in tests %}
{% if test.parametrized %}
@pytest.mark.parametrize("{{ test.param_names }}", {{ test.test_cases }})
{% endif %}
def test_{{ test.name }}({% if test.parametrized %}{{ test.param_names }}{% endif %}{% if fixtures %}{% for fixture in fixtures %}, {{ fixture.name }}{% endfor %}{% endif %}):
    """{{ test.description }}"""
    {% if test.setup %}
    # Test setup
    {% for setup_line in test.setup %}
    {{ setup_line }}
    {% endfor %}
    {% endif %}

    {% if test.is_dataset_test %}
    # Dataset-specific test logic
    {% if test.dataset_operations %}
    {% for operation in test.dataset_operations %}
    {{ operation }}
    {% endfor %}
    {% endif %}
    {% endif %}

    # Test execution
    {% for assertion in test.assertions %}
    {{ assertion }}
    {% endfor %}

    {% if test.cleanup %}
    # Test cleanup
    {% for cleanup_line in test.cleanup %}
    {{ cleanup_line }}
    {% endfor %}
    {% endif %}

{% endfor %}
'''


# ---------------------------------------------------------------------------
# Core engine class
# ---------------------------------------------------------------------------


class TestGeneratorCore:
    """
    Core test generation engine (framework-independent).

    Parses JSON specifications and produces unittest or pytest test files
    using Jinja2 templates.  All business logic lives here so that the MCP
    tool, CLI, and direct-import callers share identical behaviour.

    Args:
        config: Optional :class:`TestGeneratorConfig`.  A default config is
            used when not supplied.
    """

    def __init__(self, config: Optional[TestGeneratorConfig] = None) -> None:
        if not JINJA2_AVAILABLE:
            raise TestGeneratorExecutionError(
                "jinja2 is required for test generation; "
                "install it with: pip install jinja2"
            )
        self.config = config or TestGeneratorConfig()
        self._jinja_env = jinja2.Environment(
            loader=jinja2.BaseLoader(),
            trim_blocks=True,
            lstrip_blocks=True,
        )

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    def generate(
        self,
        name: str,
        description: str = "",
        test_specification: Union[str, Dict[str, Any], None] = None,
        output_dir: Optional[str] = None,
        harness: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Generate a test file from a JSON specification.

        Args:
            name: Name of the test suite (used for file/class naming).
            description: Human-readable description of the tests.
            test_specification: JSON string or dict with test definitions.
            output_dir: Directory to write the generated file.  Defaults to
                ``config.output_dir``.
            harness: ``"unittest"`` or ``"pytest"``.  Defaults to
                ``config.harness``.

        Returns:
            Dict with keys ``test_file``, ``test_name``, ``harness``,
            ``num_tests``, ``has_fixtures``, ``has_dataset_features``,
            ``file_size``.

        Raises:
            :class:`TestGeneratorValidationError` on bad input.
            :class:`TestGeneratorExecutionError` on I/O or rendering errors.
        """
        if not name:
            raise TestGeneratorValidationError("Test name is required")
        if not test_specification:
            raise TestGeneratorValidationError("Test specification is required")

        spec = self._parse_specification(test_specification)
        spec["name"] = name
        spec["description"] = description
        spec["class_name"] = self._to_class_name(name)
        spec["harness"] = harness or spec.get("harness") or self.config.harness
        spec = self._add_dataset_features(spec)

        resolved_dir = Path(output_dir or self.config.output_dir)
        resolved_dir.mkdir(parents=True, exist_ok=True)

        content = self._render(spec)
        filename = f"test_{name.lower().replace(' ', '_')}.py"
        dest = resolved_dir / filename
        try:
            dest.write_text(content, encoding="utf-8")
        except OSError as exc:
            raise TestGeneratorExecutionError(f"Failed to write test file: {exc}") from exc

        return {
            "test_file": str(dest),
            "test_name": name,
            "harness": spec["harness"],
            "num_tests": len(spec["tests"]),
            "has_fixtures": bool(spec.get("fixtures")),
            "has_dataset_features": any(
                t.get("is_dataset_test", False) for t in spec["tests"]
            ),
            "file_size": dest.stat().st_size,
        }

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------

    def _parse_specification(
        self, raw: Union[str, Dict[str, Any]]
    ) -> Dict[str, Any]:
        if isinstance(raw, str):
            try:
                spec: Dict[str, Any] = json.loads(raw)
            except json.JSONDecodeError as exc:
                raise TestGeneratorValidationError(
                    f"Invalid JSON specification: {exc}"
                ) from exc
        else:
            spec = dict(raw)

        if "tests" not in spec:
            raise TestGeneratorValidationError("Missing required field: 'tests'")

        spec.setdefault("imports", [])
        spec.setdefault("fixtures", [])
        spec.setdefault("harness", self.config.harness)
        return spec

    @staticmethod
    def _to_class_name(name: str) -> str:
        """Convert a test suite name to a PascalCase class name."""
        parts = name.replace("_", " ").replace("-", " ").split()
        class_name = "".join(p.capitalize() for p in parts)
        if not class_name.startswith("Test"):
            class_name = "Test" + class_name
        return class_name

    @staticmethod
    def _add_dataset_features(spec: Dict[str, Any]) -> Dict[str, Any]:
        """Inject dataset-specific imports and fixture stubs."""
        if not spec.get("dataset_imports"):
            spec["dataset_imports"] = [
                "# Dataset imports would go here",
                "# from ipfs_datasets_py import IPFSDatasets",
            ]
        if not spec.get("dataset_fixtures"):
            spec["dataset_fixtures"] = [
                {
                    "name": "sample_dataset",
                    "value": "{'text': ['hello', 'world'], 'label': [0, 1]}",
                    "description": "Sample dataset for testing",
                }
            ]
        dataset_keywords = {"dataset", "ipfs", "load", "save", "transform"}
        for test in spec["tests"]:
            test["is_dataset_test"] = any(
                kw in test.get("description", "").lower()
                for kw in dataset_keywords
            )
            if test["is_dataset_test"] and "dataset_operations" not in test:
                test["dataset_operations"] = [
                    "# Dataset operations will be added based on test description",
                    "# This is a placeholder for dataset-specific logic",
                ]
        return spec

    def _render(self, spec: Dict[str, Any]) -> str:
        """Render the Jinja2 template for the given specification."""
        spec["timestamp"] = datetime.now().isoformat()
        template_str = (
            PYTEST_TEMPLATE
            if spec["harness"].lower() == "pytest"
            else UNITTEST_TEMPLATE
        )
        return self._jinja_env.from_string(template_str).render(**spec)


# ---------------------------------------------------------------------------
# Standalone convenience function
# ---------------------------------------------------------------------------


def generate_test_file(
    name: str,
    description: str = "",
    test_specification: Union[str, Dict[str, Any], None] = None,
    output_dir: Optional[str] = None,
    harness: Optional[str] = None,
    config: Optional[TestGeneratorConfig] = None,
) -> Dict[str, Any]:
    """
    Generate a test file from a JSON specification (convenience wrapper).

    This function is the canonical entry-point shared by the MCP server tool,
    the ``ipfs-datasets`` CLI, and direct Python imports.

    Args:
        name: Test suite name.
        description: Human-readable description.
        test_specification: JSON string or dict.
        output_dir: Output directory (defaults to ``"tests"``).
        harness: ``"unittest"`` or ``"pytest"`` (defaults to ``"unittest"``).
        config: Optional :class:`TestGeneratorConfig` override.

    Returns:
        Dict with generation metadata (``test_file``, ``num_tests``, …).
    """
    engine = TestGeneratorCore(config=config)
    return engine.generate(
        name=name,
        description=description,
        test_specification=test_specification,
        output_dir=output_dir,
        harness=harness,
    )
